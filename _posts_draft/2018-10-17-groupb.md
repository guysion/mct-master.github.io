---
layout: post
title:  "Group B, day 2 of Physical computing"
date:   2018-10-18 00:30:00 +0200
categories: Physical computing
author: Mari Lesteberg, Dmitry Vasilev, Ashane Silva, Shreejay Shreshta & Eigil Aandahl
comments: true
---

<figure>
<img src="/assets/img/p_c_1.png" alt="" width="40%" />
<figcaption></figcaption>
</figure>


Today, the session was about creating an audio web application that reacts to inputs of mobile sensor data. First, we tried to identify different types of sensors and their capabilities by trying out different android and iOs sensor apps. Then the application was made based on the movements and orientation of the mobile phone.

As the previous day, we have continued on struggling with the Visual Studio Code. The first step was to test the accelerometer java script API and at least some of us actually made it work. And some of us had to edit the code to get it work on iPhone.  For some reason, Mari's computer or phone wouldn't collaborate today, but later the same day, she managed to do it from home, on her desktop computer.    
The hand waving exercise was fun. We managed to flash colors and sounds from our phones. Everyone were playing with their phones as a child found a new toy. 

Shreejay represented the group in Trondheim today as Eigil was sick. He managed to load sounds from freesound.org in the java scripts and was able to switch the sounds by hand waving his cell phone. Dmitry and Ashane tried adding sounds from the previous days recording and it worked to some extent. It was fascinating that we could control the frequencies, volume and other variables by just gradually tilting, moving up, down and sideways. However, In our Final performance, Dmitry's phone was working really good but some of our phones started crashing several times. So Ashane had to play with the different applications in Tone.js.

It was a new and challenging experince for all of us but fun! compared to the previous performance we did with laptops we identified certain differences. we used more our body movements in a much expressive way with the sounds. but the lapetops seems pretty good to keep up with beat and beign synced together in aperformance.  

Here are some pictures from the day's activities:
   
<figure>
<img src="/assets/img/p_c_2.png" alt="" width="40%" />
<figcaption></figcaption>
</figure>

<figure>
<img src="/assets/img/p_c_3.png" alt="" width="40%" />
<figcaption></figcaption>
</figure>

<figure>
<img src="/assets/img/p_c_4.jpg" alt="" width="40%" />
<figcaption></figcaption>
</figure>


<iframe width="560" height="315" src="https://www.youtube.com/embed/Nkp9KtFcKJg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


<iframe width="560" height="315" src="https://www.youtube.com/embed/wFbc8oNmZVw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>


At last my phone just ended up snoring.

<iframe width="560" height="315" src="https://www.youtube.com/embed/2808ZNwkuFU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

I guess that was a sign telling that it was time to go to bed.

